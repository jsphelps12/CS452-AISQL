{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsphelps12/CS452-AISQL/blob/main/embed/VectorDB_Lab_CS452_(starter).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4UOUNsUTsvcn"
      },
      "outputs": [],
      "source": [
        "# Download datasets from kaggle\n",
        "\n",
        "import json\n",
        "import os\n",
        "\n",
        "if not os.path.exists(\"lex-fridman-text-embedding-3-large-128.zip\"):\n",
        "  kaggle_json = {\"username\": \"michaeltreynolds\",\"key\": \"149701be742f30a8a0526762c61beea0\"}\n",
        "  kaggle_dir = os.path.join(os.path.expanduser(\"~\"), \".kaggle\")\n",
        "  os.makedirs(kaggle_dir, exist_ok=True)\n",
        "  kaggle_config_path = os.path.join(kaggle_dir, \"kaggle.json\")\n",
        "  with open(kaggle_config_path, 'w') as f:\n",
        "    json.dump(kaggle_json, f)\n",
        "\n",
        "  !kaggle datasets download -d michaeltreynolds/lex-fridman-text-embedding-3-large-128\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip kaggle data\n",
        "\n",
        "!unzip lex-fridman-text-embedding-3-large-128.zip\n",
        "!unzip lex-fridman-text-embedding-3-large-128/*.zip\n"
      ],
      "metadata": {
        "id": "h3swnD70x4FG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "557ddbcc-6109-4311-ffcc-03fbbd013b25"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  lex-fridman-text-embedding-3-large-128.zip\n",
            "replace documents/documents/batch_request_0lw3vrQqdWbdBRurTGNMHU76.jsonl? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "unzip:  cannot find or open lex-fridman-text-embedding-3-large-128/*.zip, lex-fridman-text-embedding-3-large-128/*.zip.zip or lex-fridman-text-embedding-3-large-128/*.zip.ZIP.\n",
            "\n",
            "No zipfiles found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use specific libraries\n",
        "!pip install datasets==2.20.0 psycopg2==2.9.9 pgcopy==1.6.0\n",
        "import psycopg2"
      ],
      "metadata": {
        "id": "SYDFzWfv4HLW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1406a905-073d-4732-fb9c-aa360c217ae3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets==2.20.0 in /usr/local/lib/python3.12/dist-packages (2.20.0)\n",
            "Requirement already satisfied: psycopg2==2.9.9 in /usr/local/lib/python3.12/dist-packages (2.9.9)\n",
            "Requirement already satisfied: pgcopy==1.6.0 in /usr/local/lib/python3.12/dist-packages (1.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets==2.20.0) (3.19.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets==2.20.0) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.20.0) (18.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.12/dist-packages (from datasets==2.20.0) (0.7)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.20.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==2.20.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets==2.20.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets==2.20.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==2.20.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets==2.20.0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets==2.20.0) (2024.5.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets==2.20.0) (3.12.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.12/dist-packages (from datasets==2.20.0) (0.35.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==2.20.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets==2.20.0) (6.0.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from pgcopy==1.6.0) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.20.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.20.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.20.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.20.0) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.20.0) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.20.0) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.20.0) (1.20.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21.2->datasets==2.20.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21.2->datasets==2.20.0) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==2.20.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==2.20.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==2.20.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==2.20.0) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.20.0) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.20.0) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.20.0) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get your own trial account at timescaledb and paste your own connection string\n",
        "\n",
        "#TODO\n",
        "CONNECTION = \"postgres://tsdbadmin:c5rwkl6n2bodpp3a@akjq0ow9n3.fxozb0sk8r.tsdb.cloud.timescale.com:35812/tsdb?sslmode=require\""
      ],
      "metadata": {
        "id": "ukT4dY-z25XG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use this if you want to start over on your postgres table!\n",
        "\n",
        "DROP_TABLE = \"DROP TABLE IF EXISTS podcast, segment\"\n",
        "with psycopg2.connect(CONNECTION) as conn:\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(DROP_TABLE)\n",
        "    conn.commit() # Commit the changes\n"
      ],
      "metadata": {
        "id": "gpp_3EuU3SN-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Useful function that takes a pd.DataFrame and copies it directly into a table.\n",
        "\n",
        "import pandas as pd\n",
        "import io\n",
        "import psycopg2\n",
        "\n",
        "from typing import List\n",
        "\n",
        "def fast_pg_insert(df: pd.DataFrame, connection: str, table_name: str, columns: List[str]) -> None:\n",
        "    \"\"\"\n",
        "        Inserts data from a pandas DataFrame into a PostgreSQL table using the COPY command for fast insertion.\n",
        "\n",
        "        Parameters:\n",
        "        df (pd.DataFrame): The DataFrame containing the data to be inserted.\n",
        "        connection (str): The connection string to the PostgreSQL database.\n",
        "        table_name (str): The name of the target table in the PostgreSQL database.\n",
        "        columns (List[str]): A list of column names in the target table that correspond to the DataFrame columns.\n",
        "\n",
        "        Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    conn = psycopg2.connect(connection)\n",
        "    _buffer = io.StringIO()\n",
        "    df.to_csv(_buffer, sep=\";\", index=False, header=False)\n",
        "    _buffer.seek(0)\n",
        "    with conn.cursor() as c:\n",
        "        c.copy_from(\n",
        "            file=_buffer,\n",
        "            table=table_name,\n",
        "            sep=\";\",\n",
        "            columns=columns,\n",
        "            null=''\n",
        "        )\n",
        "    conn.commit()\n",
        "    conn.close()"
      ],
      "metadata": {
        "id": "wZDxdvoP4Fov"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Database Schema\n",
        "We will create a database with two tables: podcast and segment:\n",
        "\n",
        "**podcast**\n",
        "\n",
        "- PK: id\n",
        " - The unique podcast id found in the huggingface data (i,e., TRdL6ZzWBS0  is the ID for Jed Buchwald: Isaac Newton and the Philosophy of Science | Lex Fridman Podcast #214)\n",
        "- title\n",
        " - The title of podcast (ie., Jed Buchwald: Isaac Newton and the Philosophy of Science | Lex Fridman Podcast #214)\n",
        "\n",
        "**segment**\n",
        "\n",
        "- PK: id\n",
        " - the unique identifier for the podcast segment. This was created by concatenating the podcast idx and the segment index together (ie., \"0;1\") is the 0th podcast and the 1st segment\n",
        "This is present in the as the \"custom_id\" field in the `embedding.jsonl` and batch_request.jsonl files\n",
        "- start_time\n",
        " - The start timestamp of the segment\n",
        "- end_time\n",
        " - The end timestamp of the segment\n",
        "- content\n",
        " - The raw text transcription of the podcast\n",
        "- embedding\n",
        " - the 128 dimensional vector representation of the text\n",
        "- FK: podcast_id\n",
        " - foreign key to podcast.id"
      ],
      "metadata": {
        "id": "7Y2HkhMZmHFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample document:\n",
        "# {\n",
        "#   \"custom_id\": \"89:115\",\n",
        "#   \"url\": \"/v1/embeddings\",\n",
        "#   \"method\": \"POST\",\n",
        "#   \"body\": {\n",
        "#     \"input\": \" have been possible without these approaches?\",\n",
        "#     \"model\": \"text-embedding-3-large\",\n",
        "#     \"dimensions\": 128,\n",
        "#     \"metadata\": {\n",
        "#       \"title\": \"Podcast: Boris Sofman: Waymo, Cozmo, Self-Driving Cars, and the Future of Robotics | Lex Fridman Podcast #241\",\n",
        "#       \"podcast_id\": \"U_AREIyd0Fc\",\n",
        "#       \"start_time\": 484.52,\n",
        "#       \"stop_time\": 487.08\n",
        "#     }\n",
        "#   }\n",
        "# }\n",
        "\n",
        "# Sample embedding:\n",
        "# {\n",
        "#   \"id\": \"batch_req_QZBmHS7FBiVABxcsGiDx2THJ\",\n",
        "#   \"custom_id\": \"89:115\",\n",
        "#   \"response\": {\n",
        "#     \"status_code\": 200,\n",
        "#     \"request_id\": \"7a55eba082c70aca9e7872d2b694f095\",\n",
        "#     \"body\": {\n",
        "#       \"object\": \"list\",\n",
        "#       \"data\": [\n",
        "#         {\n",
        "#           \"object\": \"embedding\",\n",
        "#           \"index\": 0,\n",
        "#           \"embedding\": [\n",
        "#             0.0035960325,\n",
        "#             126 more lines....\n",
        "#             -0.093248844\n",
        "#           ]\n",
        "#         }\n",
        "#       ],\n",
        "#       \"model\": \"text-embedding-3-large\",\n",
        "#       \"usage\": {\n",
        "#         \"prompt_tokens\": 7,\n",
        "#         \"total_tokens\": 7\n",
        "#       }\n",
        "#     }\n",
        "#   },\n",
        "#   \"error\": null\n",
        "# }"
      ],
      "metadata": {
        "id": "3EZuFdc9m9uP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create table statements that you'll write\n",
        "#TODO\n",
        "\n",
        "\n",
        "# may need to run this to enable vector data type if you didn't select AI in service\n",
        "# CREATE_EXTENSION = \"CREATE EXTENSION vector\"\n",
        "\n",
        "# TODO: Add create table statement\n",
        "CREATE_PODCAST_TABLE = \"\"\"\n",
        "CREATE TABLE podcast (\n",
        "    id VARCHAR(255) PRIMARY KEY,\n",
        "    title VARCHAR(255)\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "# TODO: Add create table statement\n",
        "CREATE_SEGMENT_TABLE = \"\"\"\n",
        "CREATE TABLE segment (\n",
        "    id VARCHAR(255) PRIMARY KEY,\n",
        "    start_time FLOAT,\n",
        "    end_time FLOAT,\n",
        "    content TEXT,\n",
        "    embedding VECTOR(128),\n",
        "    podcast_id VARCHAR(255),\n",
        "    CONSTRAINT fk_podcast\n",
        "        FOREIGN KEY(podcast_id)\n",
        "        REFERENCES podcast(id)\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "conn = psycopg2.connect(CONNECTION)\n",
        "# TODO: Create tables with psycopg2 (example: https://www.geeksforgeeks.org/executing-sql-query-with-psycopg2-in-python/)\n",
        "\n",
        "cursor = conn.cursor()\n",
        "cursor.execute(CREATE_PODCAST_TABLE)\n",
        "cursor.execute(CREATE_SEGMENT_TABLE)\n",
        "\n",
        "conn.commit()\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "bU6fFAwb5EYO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Extract needed data out of JSONL files. This may be the hard part!\n",
        "\n",
        "# TODO: What data do we need?\n",
        "# TODO: What data is in the documents jsonl files?\n",
        "# TODO: What data is in the embedding jsonl files?\n",
        "# TODO: Get some pandas data frames for our two tables so we can copy the data in!\n",
        "\n"
      ],
      "metadata": {
        "id": "v81052OY5BKW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7e44ba8",
        "outputId": "a6740955-1e6b-41d9-cb16-b877ad8c14db"
      },
      "source": [
        "import json\n",
        "import glob\n",
        "\n",
        "podcast_data = []\n",
        "segment_data = []\n",
        "\n",
        "# Process document files for podcast and segment data (content, start_time, end_time)\n",
        "document_files = glob.glob(\"documents/documents/*.jsonl\")\n",
        "for file_path in document_files:\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            data = json.loads(line)\n",
        "            metadata = data.get(\"body\", {}).get(\"metadata\", {})\n",
        "            podcast_id = metadata.get(\"podcast_id\")\n",
        "            title = metadata.get(\"title\")\n",
        "            custom_id = data.get(\"custom_id\")\n",
        "            start_time = metadata.get(\"start_time\")\n",
        "            stop_time = metadata.get(\"stop_time\")\n",
        "            content = data.get(\"body\", {}).get(\"input\")\n",
        "\n",
        "            if podcast_id and title:\n",
        "                # Collect unique podcasts\n",
        "                podcast_data.append({\"id\": podcast_id, \"title\": title})\n",
        "\n",
        "            if custom_id and start_time is not None and stop_time is not None and content is not None and podcast_id:\n",
        "                 # Collect segment data (excluding embedding for now)\n",
        "                segment_data.append({\n",
        "                    \"id\": custom_id,\n",
        "                    \"start_time\": start_time,\n",
        "                    \"end_time\": stop_time,\n",
        "                    \"content\": content,\n",
        "                    \"podcast_id\": podcast_id\n",
        "                })\n",
        "\n",
        "# Process embedding files for embedding data\n",
        "embedding_files = glob.glob(\"embedding/embedding/*.jsonl\")\n",
        "embedding_map = {} # To store embeddings by custom_id\n",
        "\n",
        "for file_path in embedding_files:\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            data = json.loads(line)\n",
        "            custom_id = data.get(\"custom_id\")\n",
        "            embedding = data.get(\"response\", {}).get(\"body\", {}).get(\"data\", [{}])[0].get(\"embedding\")\n",
        "\n",
        "            if custom_id and embedding:\n",
        "                embedding_map[custom_id] = embedding\n",
        "\n",
        "# Add embeddings to segment data\n",
        "for segment in segment_data:\n",
        "    segment[\"embedding\"] = embedding_map.get(segment[\"id\"])\n",
        "\n",
        "# Remove segments for which no embedding was found\n",
        "segment_data = [segment for segment in segment_data if segment[\"embedding\"] is not None]\n",
        "\n",
        "print(f\"Extracted {len(podcast_data)} potential podcasts and {len(segment_data)} segments with embeddings.\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted 832839 potential podcasts and 832839 segments with embeddings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(podcast_data[0])\n",
        "print(segment_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4oS7OIDNj_1",
        "outputId": "c193bef5-65db-4416-8c4d-920d7c0afdf7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'tueAcSiiqYA', 'title': 'Podcast: Jordan Ellenberg: Mathematics of High-Dimensional Shapes and Geometries | Lex Fridman Podcast #190'}\n",
            "{'id': '311:634', 'start_time': 2195.76, 'end_time': 2197.52, 'content': ' So all of those are intrinsic things, right?', 'podcast_id': 'tueAcSiiqYA', 'embedding': [-0.0012927473, -0.0044831056, -0.11136264, 0.10946503, -0.0587175, -0.13077249, -0.06300068, -0.10962769, 0.02233759, -0.17165245, -0.017092051, 0.1895442, 0.077693604, -0.0104233045, 0.07606708, 0.10463968, -0.08994675, 0.0010589346, -0.09992276, -0.015858604, 0.04166611, -0.077314086, -0.16167644, -0.008925548, -0.08219366, -0.050178252, 0.040581763, -0.09200701, -0.14410998, -0.03467206, 0.05489517, -0.02193096, 0.055952407, 0.031202143, -0.0739526, -0.0931998, 0.018108629, -0.021944514, 0.11678439, 0.050042707, -0.0067941244, -0.06961521, 0.027623791, 0.07341043, -0.12263987, 0.09894685, -0.09629019, 0.022703558, 0.061591025, 0.0005209958, 0.025292441, 0.033533495, 0.112989165, 0.024736712, 0.01387289, 0.15419443, 0.08962145, -0.19962865, -0.026390344, 0.14248346, -0.0069398335, -0.056657236, -0.2097131, -0.014950462, -0.028003313, -0.12589292, -0.0587175, -0.04445831, 0.04738605, 0.09699502, -0.048009552, 0.05676567, -0.16905001, -0.08490453, 0.04166611, -0.015587517, -0.021836078, 0.06381394, 0.059368107, 0.0050862744, 0.11591691, 0.048145097, 0.0006264657, 0.01089093, -0.01966738, 0.13261588, 0.10735055, -0.14118224, 0.070753776, 0.14172442, 0.044295657, 0.15972461, 0.0144896135, -0.051289707, 0.012144709, 0.14367625, 0.008972988, 0.03125636, 0.029196097, -0.09666971, -0.029304532, -0.089675665, -0.11830248, -0.09119375, -0.08371174, 0.05383793, 0.043699265, -0.018772792, -0.059639197, 0.12112179, -0.035539538, -0.18271281, -0.11971213, -0.013113846, 0.07801891, -0.054380104, -0.028220182, -0.11938683, 0.0860431, -0.019748706, -0.00377489, -0.02209361, 0.1863996, -0.16764036, -0.034753386, 0.08945879, 0.013073183, -0.24397853]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "podcast_df = pd.DataFrame(podcast_data)\n",
        "podcast_df = podcast_df.drop_duplicates(subset=['id'])\n",
        "# display(podcast_df.head())"
      ],
      "metadata": {
        "id": "jBLyS_d6OVq1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a15da4a4"
      },
      "source": [
        "segment_df = pd.DataFrame(segment_data)\n",
        "# display(segment_df.head())"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### Optional #####\n",
        "# In addition to the embedding and document files you might like to load\n",
        "# the full podcast raw data via the hugging face datasets library\n",
        "\n",
        "# from datasets import load_dataset\n",
        "# ds = load_dataset(\"Whispering-GPT/lex-fridman-podcast\")\n"
      ],
      "metadata": {
        "id": "xo3Y8IHYRruE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO Copy all the \"podcast\" data into the podcast postgres table!\n",
        "\n",
        "fast_pg_insert(podcast_df, CONNECTION, \"podcast\", [\"id\", \"title\"])"
      ],
      "metadata": {
        "id": "5W3f-2iTpGL0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO Copy all the \"segment\" data into the segment postgres table!\n",
        "# HINT 1: use the recommender.utils.fast_pg_insert function to insert data into the database\n",
        "# otherwise inserting the 800k documents will take a very, very long time\n",
        "# HINT 2: if you don't want to use all your memory and crash\n",
        "# colab, you'll need to either send the data up in chunks\n",
        "# or write your own function for copying it up. Alternative to chunking maybe start\n",
        "# with writing it to a CSV and then copy it up?\n",
        "\n",
        "import io\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "conn = psycopg2.connect(CONNECTION)\n",
        "\n",
        "# Write DataFrame to a temporary CSV file with manual formatting for embedding\n",
        "with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix=\".csv\") as tmp_file:\n",
        "    for index, row in segment_df.iterrows():\n",
        "        # Ensure the embedding is treated as a list of floats before joining\n",
        "        embedding_list = row['embedding']\n",
        "        if isinstance(embedding_list, str):\n",
        "             # Attempt to parse the string representation if it's already a string\n",
        "             try:\n",
        "                 embedding_list = json.loads(embedding_list)\n",
        "             except json.JSONDecodeError:\n",
        "                 # Handle cases where the string format is unexpected\n",
        "                 print(f\"Warning: Could not parse embedding string for segment {row['id']}: {embedding_list}\")\n",
        "                 embedding_list = [] # Or handle as appropriate\n",
        "\n",
        "        # Manually format the embedding as a string representation of a list\n",
        "        embedding_str = '[' + ','.join(map(str, embedding_list)) + ']'\n",
        "        # Create a list of values for the row, including the formatted embedding\n",
        "        row_values = [str(row['id']), str(row['start_time']), str(row['end_time']), str(row['content']).replace(';', '\\\\;'), embedding_str, str(row['podcast_id'])]\n",
        "        # Join the values with the separator and write to the file\n",
        "        tmp_file.write(';'.join(row_values) + '\\n')\n",
        "    tmp_file_path = tmp_file.name\n",
        "\n",
        "# Copy data from the temporary CSV file into the database\n",
        "try:\n",
        "    with conn.cursor() as c:\n",
        "        with open(tmp_file_path, 'r') as f:\n",
        "            c.copy_from(\n",
        "                file=f,\n",
        "                table=\"segment\",\n",
        "                sep=\";\",\n",
        "                columns=[\"id\", \"start_time\", \"end_time\", \"content\", \"embedding\", \"podcast_id\"],\n",
        "                null=''\n",
        "            )\n",
        "    conn.commit()\n",
        "except Exception as e:\n",
        "    conn.rollback()\n",
        "    print(f\"Error during copy: {e}\")\n",
        "finally:\n",
        "    conn.close()\n",
        "    # Clean up the temporary file\n",
        "    os.remove(tmp_file_path)"
      ],
      "metadata": {
        "id": "ZTUsciGfpahF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## This script is used to query the database\n",
        "import os\n",
        "import psycopg2\n",
        "\n",
        "\n",
        "# Write your queries\n",
        "# Q1) What are the five most similar segments to segment \"267:476\"\n",
        "# Input: \"that if we were to meet alien life at some point\"\n",
        "# For each result return the podcast name, the segment id, segment raw text,  the start time, stop time, and embedding distance\n",
        "\n",
        "conn = psycopg2.connect(CONNECTION)\n",
        "cur = conn.cursor()\n",
        "cur.execute(\"\"\"\n",
        "SELECT\n",
        "    p.title,\n",
        "    s.id,\n",
        "    s.content,\n",
        "    s.start_time,\n",
        "    s.end_time,\n",
        "    s.embedding <-> (SELECT embedding FROM segment WHERE id = '267:476') AS distance\n",
        "FROM\n",
        "    segment s\n",
        "JOIN\n",
        "    podcast p ON s.podcast_id = p.id\n",
        "ORDER BY\n",
        "    distance\n",
        "LIMIT 5;\n",
        "\"\"\")\n",
        "for row in cur.fetchall():\n",
        "  print(row)\n",
        "\n",
        "conn.commit()\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "NvkG-51G5IDe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd0f93d9-efcb-4942-e7e9-69c570f87370"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Podcast: David Silver: AlphaGo, AlphaZero, and Deep Reinforcement Learning | Lex Fridman Podcast #86', '267:476', ' that if we were to meet alien life at some point', 1336.32, 1339.4399999999998, 0.0)\n",
            "('Podcast: Ryan Graves: UFOs, Fighter Jets, and Aliens | Lex Fridman Podcast #308', '113:2792', ' encounters, human beings, if we were to meet another alien', 6725.62, 6729.86, 0.6483450674336982)\n",
            "('Podcast: Richard Dawkins: Evolution, Intelligence, Simulation, and Memes | Lex Fridman Podcast #87', '268:1019', ' Suppose we did meet an alien from outer space', 2900.04, 2903.0800000000004, 0.655810731375558)\n",
            "('Podcast: Jeffrey Shainline: Neuromorphic Computing and Optoelectronic Intelligence | Lex Fridman Podcast #225', '305:3600', ' but if we think of alien civilizations out there', 9479.960000000001, 9484.04, 0.6595433341200092)\n",
            "('Podcast: Michio Kaku: Future of Humans, Aliens, Space Travel & Physics | Lex Fridman Podcast #45', '18:464', ' So I think when we meet alien life from outer space,', 1316.8600000000001, 1319.5800000000002, 0.6662026419636159)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2) What are the five most dissimilar segments to segment \"267:476\"\n",
        "# Input: \"that if we were to meet alien life at some point\"\n",
        "# For each result return the podcast name, the segment id, segment raw text, the start time, stop time, and embedding distance\n",
        "\n",
        "conn = psycopg2.connect(CONNECTION)\n",
        "cur = conn.cursor()\n",
        "cur.execute(\"\"\"\n",
        "SELECT\n",
        "    p.title,\n",
        "    s.id,\n",
        "    s.content,\n",
        "    s.start_time,\n",
        "    s.end_time,\n",
        "    s.embedding <-> (SELECT embedding FROM segment WHERE id = '267:476') AS distance\n",
        "FROM\n",
        "    segment s\n",
        "JOIN\n",
        "    podcast p ON s.podcast_id = p.id\n",
        "ORDER BY\n",
        "    distance DESC\n",
        "LIMIT 5;\n",
        "\"\"\")\n",
        "print(\"Q2 Results:\")\n",
        "for row in cur.fetchall():\n",
        "  print(row)\n",
        "\n",
        "conn.commit()\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "Dq8ePSfrw8Ix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0941e0e3-5b0b-4412-e21d-be5f2070f328"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q2 Results:\n",
            "('Podcast: Jason Calacanis: Startups, Angel Investing, Capitalism, and Friendship | Lex Fridman Podcast #161', '119:218', ' a 73 Mustang Grande in gold?', 519.96, 523.8000000000001, 1.6157687685840119)\n",
            "('Podcast: Rana el Kaliouby: Emotion AI, Social Robots, and Self-Driving Cars | Lex Fridman Podcast #322', '133:2006', ' for 94 car models.', 5818.62, 5820.82, 1.5863358321539258)\n",
            "('Podcast: Travis Stevens: Judo, Olympics, and Mental Toughness | Lex Fridman Podcast #223', '283:1488', ' when I called down to get the sauna.', 3709.34, 3711.1000000000004, 1.572552805197421)\n",
            "('Podcast: Jeremy Howard: fast.ai Deep Learning Courses and Research | Lex Fridman Podcast #35', '241:1436', ' which has all the courses pre-installed.', 4068.9, 4071.1400000000003, 1.5663321232557983)\n",
            "('Podcast: Joscha Bach: Nature of Reality, Dreams, and Consciousness | Lex Fridman Podcast #212', '307:3933', ' and very few are first class and some are budget.', 10648.64, 10650.960000000001, 1.5616341289820461)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3) What are the five most similar segments to segment '48:511'\n",
        "\n",
        "# Input: \"Is it is there something especially interesting and profound to you in terms of our current deep learning neural network, artificial neural network approaches and the whatever we do understand about the biological neural network.\"\n",
        "# For each result return the podcast name, the segment id, segment raw text,  the start time, stop time, and embedding distance\n",
        "\n",
        "conn = psycopg2.connect(CONNECTION)\n",
        "cur = conn.cursor()\n",
        "cur.execute(\"\"\"\n",
        "SELECT\n",
        "    p.title,\n",
        "    s.id,\n",
        "    s.content,\n",
        "    s.start_time,\n",
        "    s.end_time,\n",
        "    s.embedding <-> (SELECT embedding FROM segment WHERE id = '48:511') AS distance\n",
        "FROM\n",
        "    segment s\n",
        "JOIN\n",
        "    podcast p ON s.podcast_id = p.id\n",
        "ORDER BY\n",
        "    distance\n",
        "LIMIT 5;\n",
        "\"\"\")\n",
        "print(\"\\nQ3 Results:\")\n",
        "for row in cur.fetchall():\n",
        "  print(row)\n",
        "\n",
        "conn.commit()\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "dmTK02bZk3pF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6d0714e-4006-42e1-87b7-b70a7e0feaeb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Q3 Results:\n",
            "('Podcast: Matt Botvinick: Neuroscience, Psychology, and AI at DeepMind | Lex Fridman Podcast #106', '48:511', ' Is it is there something especially interesting and profound to you in terms of our current deep learning neural network, artificial neural network approaches and the whatever we do understand about the biological neural network.', 1832.84, 1846.84, 0.0)\n",
            "('Podcast: Andrew Huberman: Neuroscience of Optimal Performance | Lex Fridman Podcast #139', '155:648', ' Is there something interesting to you or fundamental to you about the circuitry of the brain', 3798.48, 3805.84, 0.652299685331962)\n",
            "('Podcast: Cal Newport: Deep Work, Focus, Productivity, Email, and Social Media | Lex Fridman Podcast #166', '61:3707', ' of what we might discover about neural networks?', 8498.02, 8500.1, 0.7121050124628524)\n",
            "('Podcast: Matt Botvinick: Neuroscience, Psychology, and AI at DeepMind | Lex Fridman Podcast #106', '48:512', \" And our brain is there. There's some there's quite a few differences. Are some of them to you either interesting or perhaps profound in terms of in terms of the gap we might want to try to close in trying to create a human level intelligence.\", 1846.84, 1865.84, 0.7195604150682745)\n",
            "('Podcast: Yann LeCun: Dark Matter of Intelligence and Self-Supervised Learning | Lex Fridman Podcast #258', '276:2642', ' Have these, I mean, small pockets of beautiful complexity. Does that, do cellular automata, do these kinds of emergence and complex systems give you some intuition or guide your understanding of machine learning systems and neural networks and so on?', 8628.16, 8646.16, 0.7357217330661501)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q4) What are the five most similar segments to segment '51:56'\n",
        "\n",
        "# Input: \"But what about like the fundamental physics of dark energy? Is there any understanding of what the heck it is?\"\n",
        "# For each result return the podcast name, the segment id, segment raw text,  the start time, stop time, and embedding distance\n",
        "\n",
        "conn = psycopg2.connect(CONNECTION)\n",
        "cur = conn.cursor()\n",
        "cur.execute(\"\"\"\n",
        "SELECT\n",
        "    p.title,\n",
        "    s.id,\n",
        "    s.content,\n",
        "    s.start_time,\n",
        "    s.end_time,\n",
        "    s.embedding <-> (SELECT embedding FROM segment WHERE id = '51:56') AS distance\n",
        "FROM\n",
        "    segment s\n",
        "JOIN\n",
        "    podcast p ON s.podcast_id = p.id\n",
        "ORDER BY\n",
        "    distance\n",
        "LIMIT 5;\n",
        "\"\"\")\n",
        "print(\"\\nQ4 Results:\")\n",
        "for row in cur.fetchall():\n",
        "  print(row)\n",
        "\n",
        "conn.commit()\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "jcfhAKKQk9rV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2619143c-d688-4c71-c52d-4b0f35f167f2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Q4 Results:\n",
            "('Podcast: Alex Filippenko: Supernovae, Dark Energy, Aliens & the Expanding Universe | Lex Fridman Podcast #137', '51:56', ' But what about like the fundamental physics of dark energy? Is there any understanding of what the heck it is?', 366.5, 375.0, 0.0)\n",
            "('Podcast: George Hotz: Hacking the Simulation & Learning to Drive with Neural Nets | Lex Fridman Podcast #132', '308:144', \" I mean, we don't understand dark energy, right?\", 500.44, 502.6, 0.6681965222094363)\n",
            "('Podcast: Lex Fridman: Ask Me Anything - AMA January 2021 | Lex Fridman Podcast', '243:273', \" Like, what's up with this dark matter and dark energy stuff?\", 946.22, 950.12, 0.7355511357796344)\n",
            "('Podcast: Katherine de Kleer: Planets, Moons, Asteroids & Life in Our Solar System | Lex Fridman Podcast #184', '196:685', ' being like, what the hell is dark matter and dark energy?', 2591.72, 2595.9599999999996, 0.7631141596843518)\n",
            "('Podcast: Alex Filippenko: Supernovae, Dark Energy, Aliens & the Expanding Universe | Lex Fridman Podcast #137', '51:36', ' Do we have any understanding of what the heck that thing is?', 216.0, 219.0, 0.7922019821739293)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q5) For each of the following podcast segments, find the five most similar podcast episodes. Hint: You can do this by averaging over the embedding vectors within a podcast episode.\n",
        "\n",
        "#     a) Segment \"267:476\"\n",
        "\n",
        "#     b) Segment '48:511'\n",
        "\n",
        "#     c) Segment '51:56'\n",
        "\n",
        "# For each result return the Podcast title and the embedding distance\n",
        "\n",
        "conn = psycopg2.connect(CONNECTION)\n",
        "cur = conn.cursor()\n",
        "\n",
        "# Helper function to find most similar podcasts based on average embedding of a segment\n",
        "def find_similar_podcasts_by_segment(segment_id):\n",
        "    cur.execute(\"SELECT embedding FROM segment WHERE id = %s\", (segment_id,))\n",
        "    segment_embedding = cur.fetchone()[0]\n",
        "\n",
        "    cur.execute(\"\"\"\n",
        "        SELECT\n",
        "            p.title,\n",
        "            (SELECT AVG(embedding) FROM segment WHERE podcast_id = p.id) <-> %s AS distance\n",
        "        FROM\n",
        "            podcast p\n",
        "        ORDER BY\n",
        "            distance\n",
        "        LIMIT 5;\n",
        "    \"\"\", (segment_embedding,))\n",
        "    return cur.fetchall()\n",
        "\n",
        "print(\"\\nQ5 Results:\")\n",
        "print(\"a) Most similar podcasts to segment '267:476':\")\n",
        "for row in find_similar_podcasts_by_segment('267:476'):\n",
        "    print(row)\n",
        "\n",
        "print(\"\\nb) Most similar podcasts to segment '48:511':\")\n",
        "for row in find_similar_podcasts_by_segment('48:511'):\n",
        "    print(row)\n",
        "\n",
        "print(\"\\nc) Most similar podcasts to segment '51:56':\")\n",
        "for row in find_similar_podcasts_by_segment('51:56'):\n",
        "    print(row)\n",
        "\n",
        "\n",
        "conn.commit()\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "OT4yTTn4k_iX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "983066d9-29d1-415b-86e4-8dd392db7116"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Q5 Results:\n",
            "a) Most similar podcasts to segment '267:476':\n",
            "('Podcast: Sara Walker: The Origin of Life on Earth and Alien Worlds | Lex Fridman Podcast #198', 0.7828978136062058)\n",
            "('Podcast: Martin Rees: Black Holes, Alien Life, Dark Matter, and the Big Bang | Lex Fridman Podcast #305', 0.7879499391348677)\n",
            "('Podcast: Max Tegmark: Life 3.0 | Lex Fridman Podcast #1', 0.7886898936177833)\n",
            "('Podcast: Sean Carroll: The Nature of the Universe, Life, and Intelligence | Lex Fridman Podcast #26', 0.7890653326909047)\n",
            "('Podcast: Nick Bostrom: Simulation and Superintelligence | Lex Fridman Podcast #83', 0.7911210354871258)\n",
            "\n",
            "b) Most similar podcasts to segment '48:511':\n",
            "('Podcast: Matt Botvinick: Neuroscience, Psychology, and AI at DeepMind | Lex Fridman Podcast #106', 0.7481194602869561)\n",
            "('Podcast: Christof Koch: Consciousness | Lex Fridman Podcast #2', 0.7537802160985114)\n",
            "('Podcast: Dileep George: Brain-Inspired AI | Lex Fridman Podcast #115', 0.7605153285431108)\n",
            "('Podcast: Tomaso Poggio: Brains, Minds, and Machines | Lex Fridman Podcast #13', 0.7615547981858913)\n",
            "('Podcast: Elon Musk: Neuralink, AI, Autopilot, and the Pale Blue Dot | Lex Fridman Podcast #49', 0.7761520375527844)\n",
            "\n",
            "c) Most similar podcasts to segment '51:56':\n",
            "('Podcast: Sean Carroll: Quantum Mechanics and the Many-Worlds Interpretation | Lex Fridman Podcast #47', 0.7767144344304333)\n",
            "('Podcast: Alex Filippenko: Supernovae, Dark Energy, Aliens & the Expanding Universe | Lex Fridman Podcast #137', 0.8000715134366765)\n",
            "('Podcast: Stephen Wolfram: Fundamental Theory of Physics, Life, and the Universe | Lex Fridman Podcast #124', 0.8080714284866961)\n",
            "('Podcast: Donald Hoffman: Reality is an Illusion - How Evolution Hid the Truth | Lex Fridman Podcast #293', 0.8165829845943797)\n",
            "('Podcast: Cumrun Vafa: String Theory | Lex Fridman Podcast #204', 0.8173474813502656)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q6) For podcast episode id = VeH7qKZr0WI, find the five most similar podcast episodes. Hint: you can do a similar averaging procedure as Q5\n",
        "\n",
        "# Input Episode: \"Balaji Srinivasan: How to Fix Government, Twitter, Science, and the FDA | Lex Fridman Podcast #331\"\n",
        "# For each result return the Podcast title and the embedding distance\n",
        "\n",
        "conn = psycopg2.connect(CONNECTION)\n",
        "cur = conn.cursor()\n",
        "\n",
        "# Helper function to get average embedding for a podcast\n",
        "def get_average_embedding(podcast_id):\n",
        "    cur.execute(\"SELECT AVG(embedding) FROM segment WHERE podcast_id = %s\", (podcast_id,))\n",
        "    return cur.fetchone()[0]\n",
        "\n",
        "# Get the average embedding for the input podcast\n",
        "input_podcast_id = 'VeH7qKZr0WI'\n",
        "input_podcast_embedding = get_average_embedding(input_podcast_id)\n",
        "\n",
        "cur.execute(\"\"\"\n",
        "    SELECT\n",
        "        p.title,\n",
        "        (SELECT AVG(embedding) FROM segment WHERE podcast_id = p.id) <-> %s AS distance\n",
        "    FROM\n",
        "        podcast p\n",
        "    ORDER BY\n",
        "        distance\n",
        "    LIMIT 5;\n",
        "\"\"\", (input_podcast_embedding,))\n",
        "\n",
        "print(\"\\nQ6 Results:\")\n",
        "for row in cur.fetchall():\n",
        "    print(row)\n",
        "\n",
        "\n",
        "conn.commit()\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "_oKIVjn4lBYD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5cb26b4-1b83-457a-b703-36a7c16c92b5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Q6 Results:\n",
            "('Podcast: Balaji Srinivasan: How to Fix Government, Twitter, Science, and the FDA | Lex Fridman Podcast #331', 0.0)\n",
            "('Podcast: Tyler Cowen: Economic Growth & the Fight Against Conformity & Mediocrity | Lex Fridman Podcast #174', 0.11950104556214838)\n",
            "('Podcast: Eric Weinstein: Difficult Conversations, Freedom of Speech, and Physics | Lex Fridman Podcast #163', 0.1257139025632404)\n",
            "('Podcast: Michael Malice and Yaron Brook: Ayn Rand, Human Nature, and Anarchy | Lex Fridman Podcast #178', 0.12842690324343972)\n",
            "('Podcast: Steve Keen: Marxism, Capitalism, and Economics | Lex Fridman Podcast #303', 0.12916269225753493)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deliverables\n",
        "You will turn in a ZIP or PDF file containing all your code and a PDF file with the queries and results for questions 1-7."
      ],
      "metadata": {
        "id": "WBZVtZP4lDO2"
      }
    }
  ]
}